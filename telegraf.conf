		[agent]
				interval = "20s"
				round_interval = true
				metric_batch_size = 1000
				metric_buffer_limit = 10000
				collection_jitter = "0s"
				flush_interval = "10s"
				flush_jitter = "0s"

# Inputs
		[[inputs.docker]]
				endpoint = "unix:///var/run/docker.sock"
				gather_services = false
				container_name_include = []
				timeout = "5s"
				perdevice = true
				total = true

		[[inputs.docker_log]]
				endpoint = "unix:///var/run/docker.sock"
				container_name_include = []
				container_name_exclude = ["collector", "logs-db", "metrics", "dozzle", "grafana"]
				timeout = "5s"
				data_format = "json"

		[[inputs.prometheus]]
				urls = ["http://portal:9568/metrics", "http://proxy:8082/metrics"]
				metric_version = 2

# Outputs
		# metrics output to VM
		[[outputs.http]]
				url = "http://metrics:8428/api/v1/write"
				data_format = "prometheusremotewrite"
				[outputs.http.headers]
						Content-Type = "application/x-protobuf"
						Content-Encoding = "snappy"
						X-Prometheus-Remote-Write-Version = "0.1.0"
				namedrop = ["docker_log"]

		# send the logs to VML
		[[outputs.elasticsearch]]
				urls = ["http://logs-db:9428/insert/elasticsearch/"]
				index_name = "docker-logs"
				use_json_for_batch = true
				namepass = ["docker_log"]
